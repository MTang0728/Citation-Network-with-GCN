{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import spektral\n",
    "import tensorflow as tf\n",
    "from spektral.layers import GraphConv\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dropout\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform GCN on the Cora dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset\n"
     ]
    }
   ],
   "source": [
    "## load cora data set\n",
    "cora_A, cora_X, cora_L, cora_train_mask, cora_val_mask, cora_test_mask = spektral.datasets.citation.load_data(dataset_name='cora',\n",
    "                                                                                                              normalize_features=False, \n",
    "                                                                                                              random_split=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cora_A - adjacency matrix\n",
    "\n",
    "cora_X - feature matrix (doc by term)\n",
    "\n",
    "cora_L - label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of nodes, features and classes\n",
    "num_cora_nodes = cora_A.shape[0]\n",
    "num_cora_features = cora_X.shape[1]\n",
    "num_cora_classes = cora_L.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of cora Adjacency Matrix: 2708 x 2708\n",
      "number of cora features (number of termrs):  1433\n",
      "number of cora classes:  7\n"
     ]
    }
   ],
   "source": [
    "# print out attributes\n",
    "print('shape of cora Adjacency Matrix: {} x {}'.format(num_cora_nodes, num_cora_nodes))\n",
    "print('number of cora features (number of termrs): ', num_cora_features)\n",
    "print('number of cora classes: ', num_cora_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([351, 217, 418, 818, 426, 298, 180])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the distribution of each class for balance\n",
    "cora_L.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define feature and adjacency input to the first GCN layer\n",
    "cora_X_in = Input(shape = (num_cora_features, ))\n",
    "cora_A_in = Input(shape = (num_cora_nodes, ), sparse = True)\n",
    "# construct 3 layers of GCN, features beuing reduced to\n",
    "# 64, 32 and 7 (number of classes)\n",
    "# use drop out of 0.5 to minimize overfitting\n",
    "cora_X_1 = GraphConv(64, 'relu')([cora_X_in, cora_A_in])\n",
    "cora_X_1 = Dropout(0.5)(cora_X_1)\n",
    "cora_X_2 = GraphConv(32, 'relu')([cora_X_1, cora_A_in])\n",
    "cora_X_2 = Dropout(0.5)(cora_X_2)\n",
    "cora_X_3 = GraphConv(num_cora_classes, 'softmax')([cora_X_2, cora_A_in])\n",
    "# use keras functional API to construct a GCN model\n",
    "cora_model = Model(inputs = [cora_X_in, cora_A_in], outputs = cora_X_3, name = 'cora_GCN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess adjacency matrix to add self-loops and scale edge weights\n",
    "cora_A = GraphConv.preprocess(cora_A).astype('f4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cora_GCN_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1433)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 2708)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv (GraphConv)          (None, 64)           91776       input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64)           0           graph_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_1 (GraphConv)        (None, 32)           2080        dropout[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           graph_conv_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_2 (GraphConv)        (None, 7)            231         dropout_1[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 94,087\n",
      "Trainable params: 94,087\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "cora_model.compile(optimizer = 'adam',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             weighted_metrics = ['acc', tf.keras.metrics.AUC()])\n",
    "cora_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of epochs\n",
    "cora_epochs = 50\n",
    "# Prepare data\n",
    "cora_X = cora_X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 840ms/step - loss: 0.1004 - acc: 0.2071 - auc: 0.5384 - val_loss: 0.3588 - val_acc: 0.2340 - val_auc: 0.5288\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.1001 - acc: 0.2071 - auc: 0.5895 - val_loss: 0.3578 - val_acc: 0.2940 - val_auc: 0.5820\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.0994 - acc: 0.2857 - auc: 0.6464 - val_loss: 0.3567 - val_acc: 0.3580 - val_auc: 0.6209\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.0986 - acc: 0.4214 - auc: 0.7538 - val_loss: 0.3556 - val_acc: 0.4240 - val_auc: 0.6602\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.0979 - acc: 0.5214 - auc: 0.7936 - val_loss: 0.3544 - val_acc: 0.4740 - val_auc: 0.6942\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.0968 - acc: 0.5429 - auc: 0.8377 - val_loss: 0.3531 - val_acc: 0.4980 - val_auc: 0.7150\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.0967 - acc: 0.6071 - auc: 0.8508 - val_loss: 0.3516 - val_acc: 0.5300 - val_auc: 0.7408\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.0954 - acc: 0.6143 - auc: 0.8729 - val_loss: 0.3499 - val_acc: 0.5480 - val_auc: 0.7564\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.0953 - acc: 0.6929 - auc: 0.8899 - val_loss: 0.3481 - val_acc: 0.5780 - val_auc: 0.7750\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.0940 - acc: 0.6714 - auc: 0.8945 - val_loss: 0.3462 - val_acc: 0.5920 - val_auc: 0.7882\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.0932 - acc: 0.7000 - auc: 0.8995 - val_loss: 0.3441 - val_acc: 0.6060 - val_auc: 0.7995\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.0924 - acc: 0.7071 - auc: 0.8973 - val_loss: 0.3418 - val_acc: 0.6300 - val_auc: 0.8108\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 0.0911 - acc: 0.7357 - auc: 0.9221 - val_loss: 0.3394 - val_acc: 0.6500 - val_auc: 0.8224\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.0904 - acc: 0.7214 - auc: 0.9170 - val_loss: 0.3367 - val_acc: 0.6600 - val_auc: 0.8330\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.0896 - acc: 0.7643 - auc: 0.9274 - val_loss: 0.3340 - val_acc: 0.6720 - val_auc: 0.8435\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.0879 - acc: 0.7714 - auc: 0.9296 - val_loss: 0.3311 - val_acc: 0.6820 - val_auc: 0.8498\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.0862 - acc: 0.8214 - auc: 0.9510 - val_loss: 0.3280 - val_acc: 0.6900 - val_auc: 0.8568\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.0850 - acc: 0.8214 - auc: 0.9490 - val_loss: 0.3248 - val_acc: 0.6940 - val_auc: 0.8629\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.0826 - acc: 0.8571 - auc: 0.9543 - val_loss: 0.3216 - val_acc: 0.6940 - val_auc: 0.8676\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.0816 - acc: 0.7786 - auc: 0.9489 - val_loss: 0.3182 - val_acc: 0.7080 - val_auc: 0.8710\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.0812 - acc: 0.8071 - auc: 0.9500 - val_loss: 0.3148 - val_acc: 0.7140 - val_auc: 0.8748\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.0785 - acc: 0.8214 - auc: 0.9591 - val_loss: 0.3112 - val_acc: 0.7200 - val_auc: 0.8792\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0789 - acc: 0.7929 - auc: 0.9585 - val_loss: 0.3075 - val_acc: 0.7300 - val_auc: 0.8835\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.0760 - acc: 0.8357 - auc: 0.9632 - val_loss: 0.3038 - val_acc: 0.7380 - val_auc: 0.8879\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.0736 - acc: 0.8571 - auc: 0.9654 - val_loss: 0.2999 - val_acc: 0.7360 - val_auc: 0.8906\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0736 - acc: 0.8071 - auc: 0.9592 - val_loss: 0.2958 - val_acc: 0.7420 - val_auc: 0.8947\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0716 - acc: 0.8643 - auc: 0.9714 - val_loss: 0.2918 - val_acc: 0.7480 - val_auc: 0.8982\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.0700 - acc: 0.8357 - auc: 0.9669 - val_loss: 0.2877 - val_acc: 0.7480 - val_auc: 0.9012\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.0683 - acc: 0.8714 - auc: 0.9749 - val_loss: 0.2835 - val_acc: 0.7560 - val_auc: 0.9040\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.0659 - acc: 0.8857 - auc: 0.9773 - val_loss: 0.2794 - val_acc: 0.7620 - val_auc: 0.9061\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.0639 - acc: 0.8714 - auc: 0.9816 - val_loss: 0.2753 - val_acc: 0.7720 - val_auc: 0.9085\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0640 - acc: 0.8357 - auc: 0.9794 - val_loss: 0.2711 - val_acc: 0.7720 - val_auc: 0.9098\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0619 - acc: 0.8500 - auc: 0.9749 - val_loss: 0.2670 - val_acc: 0.7740 - val_auc: 0.9117\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0609 - acc: 0.8571 - auc: 0.9749 - val_loss: 0.2627 - val_acc: 0.7780 - val_auc: 0.9142\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.0574 - acc: 0.8786 - auc: 0.9773 - val_loss: 0.2585 - val_acc: 0.7780 - val_auc: 0.9161\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0536 - acc: 0.9143 - auc: 0.9885 - val_loss: 0.2541 - val_acc: 0.7780 - val_auc: 0.9180\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.0550 - acc: 0.8929 - auc: 0.9802 - val_loss: 0.2497 - val_acc: 0.7820 - val_auc: 0.9201\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.0530 - acc: 0.8857 - auc: 0.9839 - val_loss: 0.2454 - val_acc: 0.7820 - val_auc: 0.9215\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0513 - acc: 0.8714 - auc: 0.9822 - val_loss: 0.2411 - val_acc: 0.7800 - val_auc: 0.9237\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.0493 - acc: 0.8857 - auc: 0.9831 - val_loss: 0.2368 - val_acc: 0.7840 - val_auc: 0.9253\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0477 - acc: 0.9286 - auc: 0.9904 - val_loss: 0.2325 - val_acc: 0.7840 - val_auc: 0.9268\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0452 - acc: 0.9143 - auc: 0.9875 - val_loss: 0.2283 - val_acc: 0.7820 - val_auc: 0.9282\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.0430 - acc: 0.9071 - auc: 0.9908 - val_loss: 0.2241 - val_acc: 0.7820 - val_auc: 0.9297\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.0434 - acc: 0.9000 - auc: 0.9891 - val_loss: 0.2199 - val_acc: 0.7820 - val_auc: 0.9315\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.0421 - acc: 0.9071 - auc: 0.9908 - val_loss: 0.2159 - val_acc: 0.7780 - val_auc: 0.9331\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0425 - acc: 0.8929 - auc: 0.9891 - val_loss: 0.2121 - val_acc: 0.7760 - val_auc: 0.9339\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0393 - acc: 0.9071 - auc: 0.9930 - val_loss: 0.2083 - val_acc: 0.7740 - val_auc: 0.9347\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.0381 - acc: 0.9357 - auc: 0.9907 - val_loss: 0.2048 - val_acc: 0.7760 - val_auc: 0.9352\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0345 - acc: 0.9714 - auc: 0.9966 - val_loss: 0.2014 - val_acc: 0.7760 - val_auc: 0.9366\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.0338 - acc: 0.9357 - auc: 0.9964 - val_loss: 0.1978 - val_acc: 0.7760 - val_auc: 0.9375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1422f9510>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare val data\n",
    "cora_val_data = ([cora_X, cora_A], cora_L, cora_val_mask)\n",
    "\n",
    "# Train model\n",
    "cora_model.fit([cora_X, cora_A], cora_L,\n",
    "               sample_weight = cora_train_mask,\n",
    "               validation_data = cora_val_data,\n",
    "               epochs = cora_epochs,\n",
    "               batch_size = num_cora_nodes,\n",
    "               shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3827 - acc: 0.8040 - auc: 0.9508\n",
      "Done.\n",
      "Test loss: 0.38267821073532104\n",
      "Test accuracy: 0.8040000200271606\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "eval_results = cora_model.evaluate([cora_X, cora_A], \n",
    "                                   cora_L,\n",
    "                                   sample_weight = cora_test_mask,\n",
    "                                   batch_size = num_cora_nodes)\n",
    "print('Done.\\n'\n",
    "      'Test loss: {}\\n'\n",
    "      'Test accuracy: {}'.format(*eval_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Naive Bayes Classifier for Cora dataset (Multinomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a Multinominal NB classifier class\n",
    "nb_multinomial = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert label from hot-encoding back to single value encoding\n",
    "cora_y = [list(label).index(1) + 1 for label in cora_L]\n",
    "cora_y = np.asarray(cora_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size:  1895\n",
      "test size:  813\n"
     ]
    }
   ],
   "source": [
    "# train_test split the original data\n",
    "cora_X_train, cora_X_test, cora_y_train, cora_y_test = train_test_split(cora_X, cora_y,\n",
    "                                                                       test_size = 0.3,\n",
    "                                                                       random_state = 44)\n",
    "print('train size: ', cora_X_train.shape[0])\n",
    "print('test size: ', cora_X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy on training set:  0.8981530343007915\n"
     ]
    }
   ],
   "source": [
    "# fit classiifer on training data\n",
    "nb_multinomial.fit(cora_X_train, cora_y_train)\n",
    "# make predition and evaluate on training data\n",
    "print('mean accuracy on training set: ', nb_multinomial.score(cora_X_train, cora_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy on testing set:  0.7712177121771218\n"
     ]
    }
   ],
   "source": [
    "# make predition and evaluate on testing data\n",
    "print('mean accuracy on testing set: ', nb_multinomial.score(cora_X_test, cora_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Logistic Regression Classifier for Cora dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a logistic regressor class\n",
    "LR_model = LogisticRegression(penalty = 'l2', \n",
    "                              solver = 'lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy on training set:  0.9920844327176781\n"
     ]
    }
   ],
   "source": [
    "LR_model.fit(cora_X_train, cora_y_train)\n",
    "# make predition and evaluate on training data\n",
    "print('mean accuracy on training set: ', LR_model.score(cora_X_train, cora_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy on testing set:  0.7724477244772447\n"
     ]
    }
   ],
   "source": [
    "# make predition and evaluate on testing data\n",
    "print('mean accuracy on testing set: ', LR_model.score(cora_X_test, cora_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform GCN on the PubMed dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pubmed dataset\n",
      "Pre-processing node features\n",
      "shape of pubmed Adjacency Matrix: 19717 x 19717\n",
      "number of pubmed features (number of termrs):  500\n",
      "number of pubmed classes:  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4103, 7739, 7875])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load PubMed data set\n",
    "med_A, med_X, med_L, med_train_mask, med_val_mask, med_test_mask = spektral.datasets.citation.load_data(dataset_name ='pubmed',\n",
    "                                                                                                        normalize_features = True, \n",
    "                                                                                                        random_split = False)\n",
    "\n",
    "num_med_nodes = med_A.shape[0]\n",
    "num_med_features = med_X.shape[1]\n",
    "num_med_classes = med_L.shape[1]\n",
    "\n",
    "# print out attributes\n",
    "print('shape of pubmed Adjacency Matrix: {} x {}'.format(num_med_nodes, num_med_nodes))\n",
    "print('number of pubmed features (number of termrs): ', num_med_features)\n",
    "print('number of pubmed classes: ', num_med_classes)\n",
    "\n",
    "med_L.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"med_GCN_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 19717)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_3 (GraphConv)        (None, 32)           16032       input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           graph_conv_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_4 (GraphConv)        (None, 8)            264         dropout_2[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 8)            0           graph_conv_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_5 (GraphConv)        (None, 3)            27          dropout_3[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 16,323\n",
      "Trainable params: 16,323\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "med_X_in = Input(shape = (num_med_features, ))\n",
    "med_A_in = Input(shape = (num_med_nodes, ), sparse = True)\n",
    "\n",
    "med_X_1 = GraphConv(32, 'relu')([med_X_in, med_A_in])\n",
    "med_X_1 = Dropout(0.5)(med_X_1)\n",
    "med_X_2 = GraphConv(8, 'relu')([med_X_1, med_A_in])\n",
    "med_X_2 = Dropout(0.5)(med_X_2)\n",
    "med_X_3 = GraphConv(num_med_classes, 'softmax')([med_X_2, med_A_in])\n",
    "\n",
    "med_model = Model(inputs = [med_X_in, med_A_in], outputs = med_X_3, name = 'med_GCN_model')\n",
    "\n",
    "med_A = GraphConv.preprocess(med_A).astype('f4')\n",
    "# compile model\n",
    "med_model.compile(optimizer = 'adam',\n",
    "                  loss = 'categorical_crossentropy',\n",
    "                  weighted_metrics = ['acc', tf.keras.metrics.AUC()])\n",
    "med_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.3500 - auc_1: 0.5161 - val_loss: 0.0279 - val_acc: 0.2140 - val_auc_1: 0.5049\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.3000 - auc_1: 0.5710 - val_loss: 0.0279 - val_acc: 0.2180 - val_auc_1: 0.5074\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.2667 - auc_1: 0.5558 - val_loss: 0.0279 - val_acc: 0.2560 - val_auc_1: 0.5069\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.3500 - auc_1: 0.5597 - val_loss: 0.0279 - val_acc: 0.2780 - val_auc_1: 0.5103\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4167 - auc_1: 0.5753 - val_loss: 0.0279 - val_acc: 0.2960 - val_auc_1: 0.5057\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.3667 - auc_1: 0.5658 - val_loss: 0.0279 - val_acc: 0.2940 - val_auc_1: 0.5039\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4000 - auc_1: 0.5614 - val_loss: 0.0279 - val_acc: 0.3080 - val_auc_1: 0.4986\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4500 - auc_1: 0.6118 - val_loss: 0.0279 - val_acc: 0.3180 - val_auc_1: 0.5051\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4000 - auc_1: 0.5939 - val_loss: 0.0279 - val_acc: 0.3240 - val_auc_1: 0.5026\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4833 - auc_1: 0.5858 - val_loss: 0.0279 - val_acc: 0.3180 - val_auc_1: 0.4995\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.3833 - auc_1: 0.5744 - val_loss: 0.0279 - val_acc: 0.3080 - val_auc_1: 0.5082\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4333 - auc_1: 0.6057 - val_loss: 0.0279 - val_acc: 0.2960 - val_auc_1: 0.5110\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4000 - auc_1: 0.5753 - val_loss: 0.0279 - val_acc: 0.2900 - val_auc_1: 0.5102\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.3500 - auc_1: 0.6013 - val_loss: 0.0279 - val_acc: 0.2960 - val_auc_1: 0.5088\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4333 - auc_1: 0.6189 - val_loss: 0.0279 - val_acc: 0.2980 - val_auc_1: 0.5103\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4167 - auc_1: 0.6395 - val_loss: 0.0278 - val_acc: 0.3000 - val_auc_1: 0.5120\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.3167 - auc_1: 0.5492 - val_loss: 0.0278 - val_acc: 0.3120 - val_auc_1: 0.5147\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4667 - auc_1: 0.5997 - val_loss: 0.0278 - val_acc: 0.3260 - val_auc_1: 0.5154\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4000 - auc_1: 0.6388 - val_loss: 0.0278 - val_acc: 0.3380 - val_auc_1: 0.5221\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4333 - auc_1: 0.6098 - val_loss: 0.0278 - val_acc: 0.3480 - val_auc_1: 0.5336\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4000 - auc_1: 0.6244 - val_loss: 0.0278 - val_acc: 0.3640 - val_auc_1: 0.5384\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4500 - auc_1: 0.6553 - val_loss: 0.0278 - val_acc: 0.3740 - val_auc_1: 0.5409\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4500 - auc_1: 0.6710 - val_loss: 0.0278 - val_acc: 0.3860 - val_auc_1: 0.5422\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4000 - auc_1: 0.6356 - val_loss: 0.0278 - val_acc: 0.3980 - val_auc_1: 0.5465\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4667 - auc_1: 0.6766 - val_loss: 0.0278 - val_acc: 0.4100 - val_auc_1: 0.5485\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4333 - auc_1: 0.6403 - val_loss: 0.0278 - val_acc: 0.4240 - val_auc_1: 0.5486\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.3833 - auc_1: 0.6182 - val_loss: 0.0278 - val_acc: 0.4240 - val_auc_1: 0.5548\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4833 - auc_1: 0.6551 - val_loss: 0.0278 - val_acc: 0.4240 - val_auc_1: 0.5601\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4833 - auc_1: 0.6399 - val_loss: 0.0278 - val_acc: 0.4420 - val_auc_1: 0.5669\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4667 - auc_1: 0.6810 - val_loss: 0.0278 - val_acc: 0.4640 - val_auc_1: 0.5736\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.5333 - auc_1: 0.7051 - val_loss: 0.0278 - val_acc: 0.4780 - val_auc_1: 0.5775\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.5167 - auc_1: 0.7399 - val_loss: 0.0278 - val_acc: 0.4820 - val_auc_1: 0.5829\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.5167 - auc_1: 0.7281 - val_loss: 0.0278 - val_acc: 0.4840 - val_auc_1: 0.5844\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.5167 - auc_1: 0.6516 - val_loss: 0.0278 - val_acc: 0.4880 - val_auc_1: 0.5849\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.5167 - auc_1: 0.7212 - val_loss: 0.0278 - val_acc: 0.4840 - val_auc_1: 0.5798\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0033 - acc: 0.5833 - auc_1: 0.7391 - val_loss: 0.0278 - val_acc: 0.4800 - val_auc_1: 0.5746\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.5833 - auc_1: 0.7154 - val_loss: 0.0278 - val_acc: 0.4700 - val_auc_1: 0.5692\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4667 - auc_1: 0.6307 - val_loss: 0.0277 - val_acc: 0.4760 - val_auc_1: 0.5753\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4667 - auc_1: 0.6860 - val_loss: 0.0277 - val_acc: 0.4700 - val_auc_1: 0.5771\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4333 - auc_1: 0.5705 - val_loss: 0.0277 - val_acc: 0.4840 - val_auc_1: 0.5792\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4833 - auc_1: 0.6701 - val_loss: 0.0277 - val_acc: 0.4880 - val_auc_1: 0.5853\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4500 - auc_1: 0.6435 - val_loss: 0.0277 - val_acc: 0.4940 - val_auc_1: 0.5906\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4667 - auc_1: 0.6644 - val_loss: 0.0277 - val_acc: 0.5020 - val_auc_1: 0.5992\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.5000 - auc_1: 0.6642 - val_loss: 0.0277 - val_acc: 0.5080 - val_auc_1: 0.6101\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4667 - auc_1: 0.6827 - val_loss: 0.0277 - val_acc: 0.5180 - val_auc_1: 0.6231\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.5833 - auc_1: 0.7274 - val_loss: 0.0277 - val_acc: 0.5060 - val_auc_1: 0.6430\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.6167 - auc_1: 0.7340 - val_loss: 0.0277 - val_acc: 0.4980 - val_auc_1: 0.6529\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4667 - auc_1: 0.6961 - val_loss: 0.0276 - val_acc: 0.4960 - val_auc_1: 0.6603\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.4667 - auc_1: 0.7056 - val_loss: 0.0276 - val_acc: 0.4800 - val_auc_1: 0.6696\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0033 - acc: 0.5167 - auc_1: 0.7110 - val_loss: 0.0276 - val_acc: 0.4860 - val_auc_1: 0.6810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1422bf390>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define number of epochs\n",
    "med_epochs = 50\n",
    "# Prepare data\n",
    "med_X = med_X.toarray()\n",
    "\n",
    "med_val_data = ([med_X, med_A], med_L, med_val_mask)\n",
    "\n",
    "med_model.fit([med_X, med_A], med_L,\n",
    "             sample_weight = med_train_mask,\n",
    "             validation_data = med_val_data,\n",
    "             epochs = med_epochs,\n",
    "             batch_size = num_med_nodes,\n",
    "             shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0553 - acc: 0.4520 - auc_1: 0.6715\n",
      "Done.\n",
      "Test loss: 0.05528887361288071\n",
      "Test accuracy: 0.4519999921321869\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "med_eval_results = med_model.evaluate([med_X, med_A], \n",
    "                                      med_L,\n",
    "                                      sample_weight = med_test_mask,\n",
    "                                      batch_size = num_med_nodes)\n",
    "print('Done.\\n'\n",
    "      'Test loss: {}\\n'\n",
    "      'Test accuracy: {}'.format(*med_eval_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform GCN on the citeseer dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading citeseer dataset\n",
      "Pre-processing node features\n",
      "shape of citeseer Adjacency Matrix: 3327 x 3327\n",
      "number of citeseer features (number of termrs):  3703\n",
      "number of citeseer classes:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/spektral/datasets/citation.py:138: RuntimeWarning: divide by zero encountered in power\n",
      "  r_inv = np.power(rowsum, -1).flatten()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([249., 590., 668., 701., 596., 508.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load Citeseer data set\n",
    "cs_A, cs_X, cs_L, cs_train_mask, cs_val_mask, cs_test_mask = spektral.datasets.citation.load_data(dataset_name ='citeseer',\n",
    "                                                                                                        normalize_features = True, \n",
    "                                                                                                        random_split = False)\n",
    "\n",
    "num_cs_nodes = cs_A.shape[0]\n",
    "num_cs_features = cs_X.shape[1]\n",
    "num_cs_classes = cs_L.shape[1]\n",
    "\n",
    "# print out attributes\n",
    "print('shape of citeseer Adjacency Matrix: {} x {}'.format(num_cs_nodes, num_cs_nodes))\n",
    "print('number of citeseer features (number of termrs): ', num_cs_features)\n",
    "print('number of citeseer classes: ', num_cs_classes)\n",
    "\n",
    "cs_L.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cs_GCN_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 3703)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 3327)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_9 (GraphConv)        (None, 64)           237056      input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64)           0           graph_conv_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_10 (GraphConv)       (None, 32)           2080        dropout_6[0][0]                  \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32)           0           graph_conv_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_11 (GraphConv)       (None, 6)            198         dropout_7[0][0]                  \n",
      "                                                                 input_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 239,334\n",
      "Trainable params: 239,334\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cs_X_in = Input(shape = (num_cs_features, ))\n",
    "cs_A_in = Input(shape = (num_cs_nodes, ), sparse = True)\n",
    "\n",
    "cs_X_1 = GraphConv(64, 'relu')([cs_X_in, cs_A_in])\n",
    "cs_X_1 = Dropout(0.5)(cs_X_1)\n",
    "cs_X_2 = GraphConv(32, 'relu')([cs_X_1, cs_A_in])\n",
    "cs_X_2 = Dropout(0.5)(cs_X_2)\n",
    "cs_X_3 = GraphConv(num_cs_classes, 'softmax')([cs_X_2, cs_A_in])\n",
    "\n",
    "cs_model = Model(inputs = [cs_X_in, cs_A_in], outputs = cs_X_3, name = 'cs_GCN_model')\n",
    "\n",
    "cs_A = GraphConv.preprocess(cs_A).astype('f4')\n",
    "# compile model\n",
    "cs_model.compile(optimizer = 'adam',\n",
    "                  loss = 'categorical_crossentropy',\n",
    "                  weighted_metrics = ['acc', tf.keras.metrics.AUC()])\n",
    "cs_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0646 - acc: 0.1917 - auc_3: 0.4983 - val_loss: 0.2693 - val_acc: 0.2380 - val_auc_3: 0.5002\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.0646 - acc: 0.2083 - auc_3: 0.4992 - val_loss: 0.2692 - val_acc: 0.2460 - val_auc_3: 0.5006\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 0.0646 - acc: 0.2333 - auc_3: 0.5100 - val_loss: 0.2692 - val_acc: 0.2760 - val_auc_3: 0.5022\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.0646 - acc: 0.2500 - auc_3: 0.5158 - val_loss: 0.2692 - val_acc: 0.2860 - val_auc_3: 0.5008\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.0646 - acc: 0.3000 - auc_3: 0.5250 - val_loss: 0.2692 - val_acc: 0.3120 - val_auc_3: 0.5012\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 0.0646 - acc: 0.2833 - auc_3: 0.5283 - val_loss: 0.2691 - val_acc: 0.3280 - val_auc_3: 0.5022\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.0646 - acc: 0.2917 - auc_3: 0.5433 - val_loss: 0.2691 - val_acc: 0.3920 - val_auc_3: 0.5044\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.0645 - acc: 0.3250 - auc_3: 0.5637 - val_loss: 0.2690 - val_acc: 0.4720 - val_auc_3: 0.5042\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 0.0645 - acc: 0.3917 - auc_3: 0.5542 - val_loss: 0.2690 - val_acc: 0.5480 - val_auc_3: 0.5084\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 0.0645 - acc: 0.4000 - auc_3: 0.5742 - val_loss: 0.2689 - val_acc: 0.5680 - val_auc_3: 0.5160\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.0645 - acc: 0.3917 - auc_3: 0.5892 - val_loss: 0.2688 - val_acc: 0.5640 - val_auc_3: 0.5329\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.0645 - acc: 0.4083 - auc_3: 0.5824 - val_loss: 0.2688 - val_acc: 0.5740 - val_auc_3: 0.5417\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.0644 - acc: 0.4583 - auc_3: 0.6098 - val_loss: 0.2687 - val_acc: 0.5760 - val_auc_3: 0.5537\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 0.0644 - acc: 0.4750 - auc_3: 0.6272 - val_loss: 0.2687 - val_acc: 0.5620 - val_auc_3: 0.5587\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.0644 - acc: 0.4000 - auc_3: 0.6281 - val_loss: 0.2686 - val_acc: 0.5440 - val_auc_3: 0.5704\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 0.0643 - acc: 0.4333 - auc_3: 0.6607 - val_loss: 0.2686 - val_acc: 0.5140 - val_auc_3: 0.5770\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 0.0643 - acc: 0.5167 - auc_3: 0.6116 - val_loss: 0.2685 - val_acc: 0.5140 - val_auc_3: 0.5810\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 0.0643 - acc: 0.4500 - auc_3: 0.6960 - val_loss: 0.2685 - val_acc: 0.5180 - val_auc_3: 0.5820\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 0.0642 - acc: 0.5083 - auc_3: 0.7072 - val_loss: 0.2684 - val_acc: 0.5140 - val_auc_3: 0.5929\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.0642 - acc: 0.5000 - auc_3: 0.6978 - val_loss: 0.2684 - val_acc: 0.5340 - val_auc_3: 0.6031\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 0.0641 - acc: 0.5500 - auc_3: 0.7218 - val_loss: 0.2683 - val_acc: 0.5560 - val_auc_3: 0.6150\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 0.0641 - acc: 0.5667 - auc_3: 0.7508 - val_loss: 0.2682 - val_acc: 0.5880 - val_auc_3: 0.6215\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 0.0640 - acc: 0.6333 - auc_3: 0.7688 - val_loss: 0.2681 - val_acc: 0.5980 - val_auc_3: 0.6267\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 0.0640 - acc: 0.6417 - auc_3: 0.7878 - val_loss: 0.2679 - val_acc: 0.6300 - val_auc_3: 0.6312\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.0640 - acc: 0.5583 - auc_3: 0.7707 - val_loss: 0.2678 - val_acc: 0.6280 - val_auc_3: 0.6509\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.0638 - acc: 0.6500 - auc_3: 0.8256 - val_loss: 0.2677 - val_acc: 0.6340 - val_auc_3: 0.6614\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 0.0638 - acc: 0.6750 - auc_3: 0.8123 - val_loss: 0.2676 - val_acc: 0.6380 - val_auc_3: 0.6717\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 0.0637 - acc: 0.6917 - auc_3: 0.8438 - val_loss: 0.2674 - val_acc: 0.6360 - val_auc_3: 0.6835\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 0.0636 - acc: 0.6917 - auc_3: 0.8478 - val_loss: 0.2673 - val_acc: 0.6400 - val_auc_3: 0.6906\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 0.0637 - acc: 0.6333 - auc_3: 0.8162 - val_loss: 0.2672 - val_acc: 0.6380 - val_auc_3: 0.7042\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 1s 551ms/step - loss: 0.0635 - acc: 0.6833 - auc_3: 0.8655 - val_loss: 0.2671 - val_acc: 0.6380 - val_auc_3: 0.7168\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 0.0635 - acc: 0.7417 - auc_3: 0.8714 - val_loss: 0.2669 - val_acc: 0.6460 - val_auc_3: 0.7282\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.0633 - acc: 0.7167 - auc_3: 0.8746 - val_loss: 0.2667 - val_acc: 0.6520 - val_auc_3: 0.7384\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.0634 - acc: 0.6167 - auc_3: 0.8595 - val_loss: 0.2666 - val_acc: 0.6560 - val_auc_3: 0.7552\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 0.0633 - acc: 0.6750 - auc_3: 0.8808 - val_loss: 0.2664 - val_acc: 0.6640 - val_auc_3: 0.7637\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 0.0630 - acc: 0.7417 - auc_3: 0.8908 - val_loss: 0.2662 - val_acc: 0.6620 - val_auc_3: 0.7763\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 0.0631 - acc: 0.6750 - auc_3: 0.8816 - val_loss: 0.2661 - val_acc: 0.6700 - val_auc_3: 0.7911\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.0629 - acc: 0.8000 - auc_3: 0.9027 - val_loss: 0.2659 - val_acc: 0.6740 - val_auc_3: 0.8060\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 0.0627 - acc: 0.8083 - auc_3: 0.9102 - val_loss: 0.2657 - val_acc: 0.6720 - val_auc_3: 0.8123\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.0628 - acc: 0.7417 - auc_3: 0.9057 - val_loss: 0.2655 - val_acc: 0.6740 - val_auc_3: 0.8207\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.0626 - acc: 0.7500 - auc_3: 0.9056 - val_loss: 0.2653 - val_acc: 0.6740 - val_auc_3: 0.8253\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.0625 - acc: 0.7750 - auc_3: 0.9206 - val_loss: 0.2651 - val_acc: 0.6720 - val_auc_3: 0.8290\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 0.0623 - acc: 0.7833 - auc_3: 0.9243 - val_loss: 0.2649 - val_acc: 0.6720 - val_auc_3: 0.8375\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.0625 - acc: 0.7333 - auc_3: 0.9037 - val_loss: 0.2646 - val_acc: 0.6680 - val_auc_3: 0.8413\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.0621 - acc: 0.7667 - auc_3: 0.9225 - val_loss: 0.2644 - val_acc: 0.6700 - val_auc_3: 0.8461\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 0.0619 - acc: 0.7750 - auc_3: 0.9238 - val_loss: 0.2642 - val_acc: 0.6580 - val_auc_3: 0.8457\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.0618 - acc: 0.7667 - auc_3: 0.9311 - val_loss: 0.2640 - val_acc: 0.6460 - val_auc_3: 0.8466\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.0617 - acc: 0.7250 - auc_3: 0.9324 - val_loss: 0.2637 - val_acc: 0.6440 - val_auc_3: 0.8502\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 0.0613 - acc: 0.7833 - auc_3: 0.9363 - val_loss: 0.2634 - val_acc: 0.6480 - val_auc_3: 0.8567\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 0.0614 - acc: 0.8500 - auc_3: 0.9365 - val_loss: 0.2631 - val_acc: 0.6480 - val_auc_3: 0.8569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x144c22150>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define number of epochs\n",
    "cs_epochs = 50\n",
    "# Prepare data\n",
    "cs_X = cs_X.toarray()\n",
    "\n",
    "cs_val_data = ([cs_X, cs_A], cs_L, cs_val_mask)\n",
    "\n",
    "cs_model.fit([cs_X, cs_A], cs_L,\n",
    "             sample_weight = cs_train_mask,\n",
    "             validation_data = cs_val_data,\n",
    "             epochs = cs_epochs,\n",
    "             batch_size = num_cs_nodes,\n",
    "             shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5255 - acc: 0.6460 - auc_3: 0.8599\n",
      "Done.\n",
      "Test loss: 0.5254522562026978\n",
      "Test accuracy: 0.6460000276565552\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "cs_eval_results = cs_model.evaluate([cs_X, cs_A], \n",
    "                                    cs_L,\n",
    "                                    sample_weight = cs_test_mask,\n",
    "                                    batch_size = num_cs_nodes)\n",
    "print('Done.\\n'\n",
    "      'Test loss: {}\\n'\n",
    "      'Test accuracy: {}'.format(*cs_eval_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
