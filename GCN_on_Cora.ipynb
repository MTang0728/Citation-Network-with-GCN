{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import spektral\n",
    "import tensorflow as tf\n",
    "from spektral.layers import GraphConv\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dropout\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform GCN on the Cora dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset\n"
     ]
    }
   ],
   "source": [
    "## load cora data set\n",
    "cora_A, cora_X, cora_L, cora_train_mask, cora_val_mask, cora_test_mask = spektral.datasets.citation.load_data(dataset_name='cora',\n",
    "                                                                                                              normalize_features=False, \n",
    "                                                                                                              random_split=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cora_A - adjacency matrix\n",
    "\n",
    "cora_X - feature matrix (doc by term)\n",
    "\n",
    "cora_L - label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of nodes, features and classes\n",
    "num_cora_nodes = cora_A.shape[0]\n",
    "num_cora_features = cora_X.shape[1]\n",
    "num_cora_classes = cora_L.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of cora Adjacency Matrix: 2708 x 2708\n",
      "number of cora features (number of termrs):  1433\n",
      "number of cora classes:  7\n"
     ]
    }
   ],
   "source": [
    "# print out attributes\n",
    "print('shape of cora Adjacency Matrix: {} x {}'.format(num_cora_nodes, num_cora_nodes))\n",
    "print('number of cora features (number of termrs): ', num_cora_features)\n",
    "print('number of cora classes: ', num_cora_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([351, 217, 418, 818, 426, 298, 180])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the distribution of each class for balance\n",
    "cora_L.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define feature and adjacency input to the first GCN layer\n",
    "cora_X_in = Input(shape = (num_cora_features, ))\n",
    "cora_A_in = Input(shape = (num_cora_nodes, ), sparse = True)\n",
    "# construct 3 layers of GCN, features beuing reduced to\n",
    "# 64, 32 and 7 (number of classes)\n",
    "# use drop out of 0.5 to minimize overfitting\n",
    "cora_X_1 = GraphConv(64, 'relu')([cora_X_in, cora_A_in])\n",
    "cora_X_1 = Dropout(0.5)(cora_X_1)\n",
    "cora_X_2 = GraphConv(32, 'relu')([cora_X_1, cora_A_in])\n",
    "cora_X_2 = Dropout(0.5)(cora_X_2)\n",
    "cora_X_3 = GraphConv(num_cora_classes, 'softmax')([cora_X_2, cora_A_in])\n",
    "# use keras functional API to construct a GCN model\n",
    "cora_model = Model(inputs = [cora_X_in, cora_A_in], outputs = cora_X_3, name = 'cora_GCN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess adjacency matrix to add self-loops and scale edge weights\n",
    "cora_A = GraphConv.preprocess(cora_A).astype('f4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cora_GCN_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 1433)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           [(None, 2708)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_18 (GraphConv)       (None, 64)           91776       input_13[0][0]                   \n",
      "                                                                 input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 64)           0           graph_conv_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_19 (GraphConv)       (None, 32)           2080        dropout_12[0][0]                 \n",
      "                                                                 input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 32)           0           graph_conv_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_20 (GraphConv)       (None, 7)            231         dropout_13[0][0]                 \n",
      "                                                                 input_14[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 94,087\n",
      "Trainable params: 94,087\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "cora_model.compile(optimizer = 'adam',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             weighted_metrics = ['acc', tf.keras.metrics.AUC()])\n",
    "cora_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of epochs\n",
    "cora_epochs = 50\n",
    "# Prepare data\n",
    "cora_X = cora_X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 756ms/step - loss: 0.1009 - acc: 0.1286 - auc_4: 0.4741 - val_loss: 0.3579 - val_acc: 0.1420 - val_auc_4: 0.5771\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.1004 - acc: 0.2286 - auc_4: 0.5325 - val_loss: 0.3568 - val_acc: 0.1720 - val_auc_4: 0.6180\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.0996 - acc: 0.2214 - auc_4: 0.6310 - val_loss: 0.3558 - val_acc: 0.2280 - val_auc_4: 0.6633\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.0990 - acc: 0.2786 - auc_4: 0.6861 - val_loss: 0.3546 - val_acc: 0.2660 - val_auc_4: 0.7017\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.0981 - acc: 0.4071 - auc_4: 0.7561 - val_loss: 0.3532 - val_acc: 0.3320 - val_auc_4: 0.7340\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.0972 - acc: 0.4214 - auc_4: 0.8083 - val_loss: 0.3517 - val_acc: 0.3660 - val_auc_4: 0.7598\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0966 - acc: 0.4357 - auc_4: 0.8319 - val_loss: 0.3499 - val_acc: 0.3940 - val_auc_4: 0.7771\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.0960 - acc: 0.4857 - auc_4: 0.8411 - val_loss: 0.3480 - val_acc: 0.4220 - val_auc_4: 0.7976\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.0946 - acc: 0.5286 - auc_4: 0.8744 - val_loss: 0.3459 - val_acc: 0.4520 - val_auc_4: 0.8114\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.0941 - acc: 0.5643 - auc_4: 0.8739 - val_loss: 0.3436 - val_acc: 0.4920 - val_auc_4: 0.8227\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0930 - acc: 0.5571 - auc_4: 0.8881 - val_loss: 0.3412 - val_acc: 0.5020 - val_auc_4: 0.8309\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0915 - acc: 0.6143 - auc_4: 0.9038 - val_loss: 0.3386 - val_acc: 0.5120 - val_auc_4: 0.8346\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.0907 - acc: 0.5857 - auc_4: 0.8979 - val_loss: 0.3358 - val_acc: 0.5140 - val_auc_4: 0.8389\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.0893 - acc: 0.6357 - auc_4: 0.9148 - val_loss: 0.3329 - val_acc: 0.5260 - val_auc_4: 0.8456\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.0878 - acc: 0.7143 - auc_4: 0.9329 - val_loss: 0.3298 - val_acc: 0.5480 - val_auc_4: 0.8505\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0866 - acc: 0.7143 - auc_4: 0.9256 - val_loss: 0.3264 - val_acc: 0.5640 - val_auc_4: 0.8538\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.0857 - acc: 0.6786 - auc_4: 0.9298 - val_loss: 0.3228 - val_acc: 0.5840 - val_auc_4: 0.8595\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0837 - acc: 0.6714 - auc_4: 0.9285 - val_loss: 0.3190 - val_acc: 0.6040 - val_auc_4: 0.8656\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 1s 584ms/step - loss: 0.0815 - acc: 0.6786 - auc_4: 0.9425 - val_loss: 0.3150 - val_acc: 0.6260 - val_auc_4: 0.8698\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 1s 931ms/step - loss: 0.0812 - acc: 0.7429 - auc_4: 0.9466 - val_loss: 0.3108 - val_acc: 0.6440 - val_auc_4: 0.8750\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 1s 926ms/step - loss: 0.0792 - acc: 0.7143 - auc_4: 0.9464 - val_loss: 0.3064 - val_acc: 0.6660 - val_auc_4: 0.8810\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 0.0766 - acc: 0.7429 - auc_4: 0.9546 - val_loss: 0.3018 - val_acc: 0.6820 - val_auc_4: 0.8861\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 1s 841ms/step - loss: 0.0754 - acc: 0.7214 - auc_4: 0.9448 - val_loss: 0.2970 - val_acc: 0.6920 - val_auc_4: 0.8920\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 0.0732 - acc: 0.7286 - auc_4: 0.9523 - val_loss: 0.2920 - val_acc: 0.7000 - val_auc_4: 0.8977\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.0723 - acc: 0.8214 - auc_4: 0.9570 - val_loss: 0.2870 - val_acc: 0.7120 - val_auc_4: 0.9017\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.0706 - acc: 0.7500 - auc_4: 0.9571 - val_loss: 0.2819 - val_acc: 0.7220 - val_auc_4: 0.9065\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0671 - acc: 0.8071 - auc_4: 0.9698 - val_loss: 0.2766 - val_acc: 0.7240 - val_auc_4: 0.9099\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.0673 - acc: 0.8143 - auc_4: 0.9689 - val_loss: 0.2714 - val_acc: 0.7300 - val_auc_4: 0.9140\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0648 - acc: 0.8143 - auc_4: 0.9726 - val_loss: 0.2661 - val_acc: 0.7400 - val_auc_4: 0.9179\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.0635 - acc: 0.8429 - auc_4: 0.9697 - val_loss: 0.2609 - val_acc: 0.7400 - val_auc_4: 0.9209\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0615 - acc: 0.8357 - auc_4: 0.9641 - val_loss: 0.2556 - val_acc: 0.7460 - val_auc_4: 0.9242\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.0584 - acc: 0.8500 - auc_4: 0.9755 - val_loss: 0.2504 - val_acc: 0.7500 - val_auc_4: 0.9270\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.0572 - acc: 0.8286 - auc_4: 0.9814 - val_loss: 0.2452 - val_acc: 0.7540 - val_auc_4: 0.9292\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0550 - acc: 0.8429 - auc_4: 0.9710 - val_loss: 0.2400 - val_acc: 0.7500 - val_auc_4: 0.9317\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.0529 - acc: 0.8429 - auc_4: 0.9808 - val_loss: 0.2350 - val_acc: 0.7520 - val_auc_4: 0.9337\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.0522 - acc: 0.8643 - auc_4: 0.9816 - val_loss: 0.2299 - val_acc: 0.7580 - val_auc_4: 0.9357\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 1s 633ms/step - loss: 0.0494 - acc: 0.8857 - auc_4: 0.9827 - val_loss: 0.2249 - val_acc: 0.7580 - val_auc_4: 0.9379\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.0473 - acc: 0.8857 - auc_4: 0.9879 - val_loss: 0.2202 - val_acc: 0.7620 - val_auc_4: 0.9388\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0460 - acc: 0.9071 - auc_4: 0.9893 - val_loss: 0.2155 - val_acc: 0.7660 - val_auc_4: 0.9407\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.0452 - acc: 0.9000 - auc_4: 0.9871 - val_loss: 0.2110 - val_acc: 0.7680 - val_auc_4: 0.9420\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.0413 - acc: 0.9214 - auc_4: 0.9921 - val_loss: 0.2068 - val_acc: 0.7700 - val_auc_4: 0.9428\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.0427 - acc: 0.9000 - auc_4: 0.9899 - val_loss: 0.2027 - val_acc: 0.7680 - val_auc_4: 0.9434\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.0415 - acc: 0.9143 - auc_4: 0.9904 - val_loss: 0.1989 - val_acc: 0.7740 - val_auc_4: 0.9439\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.0395 - acc: 0.8929 - auc_4: 0.9916 - val_loss: 0.1952 - val_acc: 0.7780 - val_auc_4: 0.9444\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.0365 - acc: 0.9357 - auc_4: 0.9911 - val_loss: 0.1918 - val_acc: 0.7780 - val_auc_4: 0.9447\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.0331 - acc: 0.9714 - auc_4: 0.9963 - val_loss: 0.1884 - val_acc: 0.7760 - val_auc_4: 0.9455\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.0346 - acc: 0.9214 - auc_4: 0.9938 - val_loss: 0.1850 - val_acc: 0.7760 - val_auc_4: 0.9456\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.0321 - acc: 0.9357 - auc_4: 0.9960 - val_loss: 0.1817 - val_acc: 0.7780 - val_auc_4: 0.9463\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.0307 - acc: 0.9500 - auc_4: 0.9956 - val_loss: 0.1786 - val_acc: 0.7760 - val_auc_4: 0.9470\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0274 - acc: 0.9357 - auc_4: 0.9968 - val_loss: 0.1757 - val_acc: 0.7740 - val_auc_4: 0.9470\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 1s 690ms/step - loss: 0.0300 - acc: 0.9286 - auc_4: 0.9897 - val_loss: 0.1728 - val_acc: 0.7780 - val_auc_4: 0.9474\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.0276 - acc: 0.9429 - auc_4: 0.9950 - val_loss: 0.1703 - val_acc: 0.7760 - val_auc_4: 0.9476\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.0261 - acc: 0.9571 - auc_4: 0.9971 - val_loss: 0.1677 - val_acc: 0.7740 - val_auc_4: 0.9480\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.0240 - acc: 0.9643 - auc_4: 0.9973 - val_loss: 0.1650 - val_acc: 0.7760 - val_auc_4: 0.9482\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0238 - acc: 0.9500 - auc_4: 0.9978 - val_loss: 0.1625 - val_acc: 0.7800 - val_auc_4: 0.9487\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0269 - acc: 0.9143 - auc_4: 0.9957 - val_loss: 0.1600 - val_acc: 0.7800 - val_auc_4: 0.9491\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0229 - acc: 0.9357 - auc_4: 0.9955 - val_loss: 0.1580 - val_acc: 0.7820 - val_auc_4: 0.9494\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.0223 - acc: 0.9714 - auc_4: 0.9982 - val_loss: 0.1560 - val_acc: 0.7820 - val_auc_4: 0.9496\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.0212 - acc: 0.9429 - auc_4: 0.9979 - val_loss: 0.1542 - val_acc: 0.7840 - val_auc_4: 0.9498\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.0193 - acc: 0.9571 - auc_4: 0.9987 - val_loss: 0.1525 - val_acc: 0.7840 - val_auc_4: 0.9497\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.0181 - acc: 0.9643 - auc_4: 0.9981 - val_loss: 0.1508 - val_acc: 0.7880 - val_auc_4: 0.9502\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.0192 - acc: 0.9429 - auc_4: 0.9978 - val_loss: 0.1494 - val_acc: 0.7900 - val_auc_4: 0.9503\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.0163 - acc: 0.9571 - auc_4: 0.9991 - val_loss: 0.1481 - val_acc: 0.7900 - val_auc_4: 0.9500\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.0170 - acc: 0.9786 - auc_4: 0.9989 - val_loss: 0.1469 - val_acc: 0.7900 - val_auc_4: 0.9498\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.0179 - acc: 0.9429 - auc_4: 0.9982 - val_loss: 0.1460 - val_acc: 0.7880 - val_auc_4: 0.9498\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.0156 - acc: 0.9643 - auc_4: 0.9992 - val_loss: 0.1454 - val_acc: 0.7840 - val_auc_4: 0.9498\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.0150 - acc: 0.9429 - auc_4: 0.9985 - val_loss: 0.1448 - val_acc: 0.7800 - val_auc_4: 0.9491\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.0145 - acc: 0.9714 - auc_4: 0.9992 - val_loss: 0.1441 - val_acc: 0.7740 - val_auc_4: 0.9489\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0136 - acc: 0.9857 - auc_4: 0.9993 - val_loss: 0.1436 - val_acc: 0.7700 - val_auc_4: 0.9488\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.0136 - acc: 0.9786 - auc_4: 0.9993 - val_loss: 0.1433 - val_acc: 0.7660 - val_auc_4: 0.9483\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.0110 - acc: 0.9857 - auc_4: 0.9999 - val_loss: 0.1430 - val_acc: 0.7620 - val_auc_4: 0.9479\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.0146 - acc: 0.9714 - auc_4: 0.9992 - val_loss: 0.1426 - val_acc: 0.7600 - val_auc_4: 0.9475\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.0134 - acc: 0.9500 - auc_4: 0.9989 - val_loss: 0.1424 - val_acc: 0.7620 - val_auc_4: 0.9470\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.0132 - acc: 0.9714 - auc_4: 0.9982 - val_loss: 0.1422 - val_acc: 0.7640 - val_auc_4: 0.9467\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.0107 - acc: 0.9929 - auc_4: 0.9998 - val_loss: 0.1419 - val_acc: 0.7640 - val_auc_4: 0.9468\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.0118 - acc: 0.9786 - auc_4: 0.9994 - val_loss: 0.1413 - val_acc: 0.7660 - val_auc_4: 0.9472\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.0111 - acc: 0.9786 - auc_4: 0.9995 - val_loss: 0.1411 - val_acc: 0.7680 - val_auc_4: 0.9469\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.0107 - acc: 0.9786 - auc_4: 0.9997 - val_loss: 0.1404 - val_acc: 0.7680 - val_auc_4: 0.9468\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.0101 - acc: 0.9857 - auc_4: 0.9996 - val_loss: 0.1397 - val_acc: 0.7720 - val_auc_4: 0.9471\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.0097 - acc: 0.9929 - auc_4: 0.9998 - val_loss: 0.1390 - val_acc: 0.7720 - val_auc_4: 0.9478\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.0102 - acc: 0.9643 - auc_4: 0.9993 - val_loss: 0.1384 - val_acc: 0.7720 - val_auc_4: 0.9480\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.0088 - acc: 0.9857 - auc_4: 0.9999 - val_loss: 0.1379 - val_acc: 0.7700 - val_auc_4: 0.9484\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.0095 - acc: 1.0000 - auc_4: 0.9999 - val_loss: 0.1375 - val_acc: 0.7700 - val_auc_4: 0.9486\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.0082 - acc: 0.9714 - auc_4: 0.9996 - val_loss: 0.1372 - val_acc: 0.7700 - val_auc_4: 0.9485\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.0080 - acc: 0.9786 - auc_4: 0.9998 - val_loss: 0.1372 - val_acc: 0.7700 - val_auc_4: 0.9481\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.0078 - acc: 0.9857 - auc_4: 0.9999 - val_loss: 0.1370 - val_acc: 0.7700 - val_auc_4: 0.9478\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.0083 - acc: 0.9786 - auc_4: 0.9998 - val_loss: 0.1369 - val_acc: 0.7700 - val_auc_4: 0.9477\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.0076 - acc: 0.9929 - auc_4: 0.9999 - val_loss: 0.1371 - val_acc: 0.7680 - val_auc_4: 0.9478\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.0075 - acc: 0.9929 - auc_4: 0.9999 - val_loss: 0.1376 - val_acc: 0.7680 - val_auc_4: 0.9472\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.0064 - acc: 1.0000 - auc_4: 1.0000 - val_loss: 0.1382 - val_acc: 0.7640 - val_auc_4: 0.9469\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.0077 - acc: 0.9786 - auc_4: 0.9997 - val_loss: 0.1389 - val_acc: 0.7660 - val_auc_4: 0.9461\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.0073 - acc: 0.9714 - auc_4: 0.9996 - val_loss: 0.1397 - val_acc: 0.7660 - val_auc_4: 0.9458\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.0078 - acc: 0.9857 - auc_4: 0.9994 - val_loss: 0.1408 - val_acc: 0.7640 - val_auc_4: 0.9450\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.0054 - acc: 0.9929 - auc_4: 1.0000 - val_loss: 0.1417 - val_acc: 0.7640 - val_auc_4: 0.9449\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.0057 - acc: 0.9929 - auc_4: 1.0000 - val_loss: 0.1423 - val_acc: 0.7640 - val_auc_4: 0.9447\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.0054 - acc: 0.9929 - auc_4: 0.9999 - val_loss: 0.1424 - val_acc: 0.7640 - val_auc_4: 0.9449\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.0063 - acc: 0.9857 - auc_4: 0.9999 - val_loss: 0.1423 - val_acc: 0.7640 - val_auc_4: 0.9451\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.0054 - acc: 0.9857 - auc_4: 0.9999 - val_loss: 0.1422 - val_acc: 0.7640 - val_auc_4: 0.9442\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.0053 - acc: 0.9786 - auc_4: 0.9999 - val_loss: 0.1424 - val_acc: 0.7640 - val_auc_4: 0.9441\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0057 - acc: 0.9929 - auc_4: 0.9997 - val_loss: 0.1424 - val_acc: 0.7640 - val_auc_4: 0.9442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x144a7c690>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare val data\n",
    "cora_val_data = ([cora_X, cora_A], cora_L, cora_val_mask)\n",
    "\n",
    "# Train model\n",
    "cora_model.fit([cora_X, cora_A], cora_L,\n",
    "               sample_weight = cora_train_mask,\n",
    "               validation_data = cora_val_data,\n",
    "               epochs = cora_epochs,\n",
    "               batch_size = num_cora_nodes,\n",
    "               shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2393 - acc: 0.7930 - auc_4: 0.9623\n",
      "Done.\n",
      "Test loss: 0.23932336270809174\n",
      "Test accuracy: 0.7929999828338623\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "eval_results = cora_model.evaluate([cora_X, cora_A], \n",
    "                                   cora_L,\n",
    "                                   sample_weight = cora_test_mask,\n",
    "                                   batch_size = num_cora_nodes)\n",
    "print('Done.\\n'\n",
    "      'Test loss: {}\\n'\n",
    "      'Test accuracy: {}'.format(*eval_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Naive Bayes Classifier for Cora dataset (Multinomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a Multinominal NB classifier class\n",
    "nb_multinomial = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert label from hot-encoding back to single value encoding\n",
    "cora_y = [list(label).index(1) + 1 for label in cora_L]\n",
    "cora_y = np.asarray(cora_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size:  1895\n",
      "test size:  813\n"
     ]
    }
   ],
   "source": [
    "# train_test split the original data\n",
    "cora_X_train, cora_X_test, cora_y_train, cora_y_test = train_test_split(cora_X, cora_y,\n",
    "                                                                       test_size = 0.3,\n",
    "                                                                       random_state = 44)\n",
    "print('train size: ', cora_X_train.shape[0])\n",
    "print('test size: ', cora_X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy on training set:  0.8981530343007915\n"
     ]
    }
   ],
   "source": [
    "# fit classiifer on training data\n",
    "nb_multinomial.fit(cora_X_train, cora_y_train)\n",
    "# make predition and evaluate on training data\n",
    "print('mean accuracy on training set: ', nb_multinomial.score(cora_X_train, cora_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy on testing set:  0.7712177121771218\n"
     ]
    }
   ],
   "source": [
    "# make predition and evaluate on testing data\n",
    "print('mean accuracy on testing set: ', nb_multinomial.score(cora_X_test, cora_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform GCN on the PubMed dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pubmed dataset\n",
      "Pre-processing node features\n",
      "shape of cora Adjacency Matrix: 19717 x 19717\n",
      "number of cora features (number of termrs):  500\n",
      "number of cora classes:  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4103, 7739, 7875])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load PubMed data set\n",
    "med_A, med_X, med_L, med_train_mask, med_val_mask, med_test_mask = spektral.datasets.citation.load_data(dataset_name ='pubmed',\n",
    "                                                                                                        normalize_features = True, \n",
    "                                                                                                        random_split = False)\n",
    "\n",
    "num_med_nodes = med_A.shape[0]\n",
    "num_med_features = med_X.shape[1]\n",
    "num_med_classes = med_L.shape[1]\n",
    "\n",
    "# print out attributes\n",
    "print('shape of pubmed Adjacency Matrix: {} x {}'.format(num_med_nodes, num_med_nodes))\n",
    "print('number of pubmed features (number of termrs): ', num_med_features)\n",
    "print('number of pubmed classes: ', num_med_classes)\n",
    "\n",
    "med_L.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"med_GCN_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 19717)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_6 (GraphConv)        (None, 32)           16032       input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           graph_conv_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_7 (GraphConv)        (None, 16)           528         dropout_4[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16)           0           graph_conv_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_8 (GraphConv)        (None, 3)            51          dropout_5[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 16,611\n",
      "Trainable params: 16,611\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "med_X_in = Input(shape = (num_med_features, ))\n",
    "med_A_in = Input(shape = (num_med_nodes, ), sparse = True)\n",
    "\n",
    "med_X_1 = GraphConv(32, 'relu')([med_X_in, med_A_in])\n",
    "med_X_1 = Dropout(0.5)(med_X_1)\n",
    "med_X_2 = GraphConv(16, 'relu')([med_X_1, med_A_in])\n",
    "med_X_2 = Dropout(0.5)(med_X_2)\n",
    "med_X_3 = GraphConv(num_med_classes, 'softmax')([med_X_2, med_A_in])\n",
    "\n",
    "med_model = Model(inputs = [med_X_in, med_A_in], outputs = med_X_3, name = 'med_GCN_model')\n",
    "\n",
    "med_A = GraphConv.preprocess(med_A).astype('f4')\n",
    "# compile model\n",
    "med_model.compile(optimizer = 'adam',\n",
    "                  loss = 'categorical_crossentropy',\n",
    "                  weighted_metrics = ['acc', tf.keras.metrics.AUC()])\n",
    "med_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x142394910>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define number of epochs\n",
    "med_epochs = 100\n",
    "# Prepare data\n",
    "med_X = med_X.toarray()\n",
    "\n",
    "med_val_data = ([med_X, med_A], med_L, med_val_mask)\n",
    "\n",
    "med_model.fit([med_X, med_A], med_L,\n",
    "             sample_weight = med_train_mask,\n",
    "             validation_data = med_val_data,\n",
    "             epochs = med_epochs,\n",
    "             batch_size = num_med_nodes,\n",
    "             shuffle = False,\n",
    "             verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0511 - acc: 0.7130 - auc_1: 0.8587\n",
      "Done.\n",
      "Test loss: 0.05111416056752205\n",
      "Test accuracy: 0.7129999995231628\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "med_eval_results = med_model.evaluate([med_X, med_A], \n",
    "                                      med_L,\n",
    "                                      sample_weight = med_test_mask,\n",
    "                                      batch_size = num_med_nodes)\n",
    "print('Done.\\n'\n",
    "      'Test loss: {}\\n'\n",
    "      'Test accuracy: {}'.format(*med_eval_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform GCN on the citeseer dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading citeseer dataset\n",
      "Pre-processing node features\n",
      "shape of citeseer Adjacency Matrix: 3327 x 3327\n",
      "number of citeseer features (number of termrs):  3703\n",
      "number of citeseer classes:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/spektral/datasets/citation.py:138: RuntimeWarning: divide by zero encountered in power\n",
      "  r_inv = np.power(rowsum, -1).flatten()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([249., 590., 668., 701., 596., 508.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load Citeseer data set\n",
    "cs_A, cs_X, cs_L, cs_train_mask, cs_val_mask, cs_test_mask = spektral.datasets.citation.load_data(dataset_name ='citeseer',\n",
    "                                                                                                        normalize_features = True, \n",
    "                                                                                                        random_split = False)\n",
    "\n",
    "num_cs_nodes = cs_A.shape[0]\n",
    "num_cs_features = cs_X.shape[1]\n",
    "num_cs_classes = cs_L.shape[1]\n",
    "\n",
    "# print out attributes\n",
    "print('shape of citeseer Adjacency Matrix: {} x {}'.format(num_cs_nodes, num_cs_nodes))\n",
    "print('number of citeseer features (number of termrs): ', num_cs_features)\n",
    "print('number of citeseer classes: ', num_cs_classes)\n",
    "\n",
    "cs_L.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cs_GCN_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 3703)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           [(None, 3327)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_15 (GraphConv)       (None, 64)           237056      input_11[0][0]                   \n",
      "                                                                 input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 64)           0           graph_conv_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_16 (GraphConv)       (None, 32)           2080        dropout_10[0][0]                 \n",
      "                                                                 input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32)           0           graph_conv_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_17 (GraphConv)       (None, 6)            198         dropout_11[0][0]                 \n",
      "                                                                 input_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 239,334\n",
      "Trainable params: 239,334\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cs_X_in = Input(shape = (num_cs_features, ))\n",
    "cs_A_in = Input(shape = (num_cs_nodes, ), sparse = True)\n",
    "\n",
    "cs_X_1 = GraphConv(64, 'relu')([cs_X_in, cs_A_in])\n",
    "cs_X_1 = Dropout(0.5)(cs_X_1)\n",
    "cs_X_2 = GraphConv(32, 'relu')([cs_X_1, cs_A_in])\n",
    "cs_X_2 = Dropout(0.5)(cs_X_2)\n",
    "cs_X_3 = GraphConv(num_cs_classes, 'softmax')([cs_X_2, cs_A_in])\n",
    "\n",
    "cs_model = Model(inputs = [cs_X_in, cs_A_in], outputs = cs_X_3, name = 'cs_GCN_model')\n",
    "\n",
    "cs_A = GraphConv.preprocess(cs_A).astype('f4')\n",
    "# compile model\n",
    "cs_model.compile(optimizer = 'adam',\n",
    "                  loss = 'categorical_crossentropy',\n",
    "                  weighted_metrics = ['acc', tf.keras.metrics.AUC()])\n",
    "cs_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x142bd5dd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define number of epochs\n",
    "cs_epochs = 100\n",
    "# Prepare data\n",
    "cs_X = cs_X.toarray()\n",
    "\n",
    "cs_val_data = ([cs_X, cs_A], cs_L, cs_val_mask)\n",
    "\n",
    "cs_model.fit([cs_X, cs_A], cs_L,\n",
    "             sample_weight = cs_train_mask,\n",
    "             validation_data = cs_val_data,\n",
    "             epochs = cs_epochs,\n",
    "             batch_size = num_cs_nodes,\n",
    "             shuffle = False,\n",
    "             verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4416 - acc: 0.6230 - auc_3: 0.8481\n",
      "Done.\n",
      "Test loss: 0.4416358172893524\n",
      "Test accuracy: 0.6230000257492065\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "cs_eval_results = cs_model.evaluate([cs_X, cs_A], \n",
    "                                    cs_L,\n",
    "                                    sample_weight = cs_test_mask,\n",
    "                                    batch_size = num_cs_nodes)\n",
    "print('Done.\\n'\n",
    "      'Test loss: {}\\n'\n",
    "      'Test accuracy: {}'.format(*cs_eval_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
